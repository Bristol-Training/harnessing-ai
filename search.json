[
  {
    "objectID": "pages/500-compliance.html",
    "href": "pages/500-compliance.html",
    "title": "Privacy & Compliance",
    "section": "",
    "text": "NoteKey Takeaways\n\n\n\n\nUse approved tools (e.g., Microsoft Copilot, Teams transcription) and always review AI outputs before sharing.\nMinimise personal data and disclose AI use in academic work to maintain transparency and integrity.\nComplete a Data Protection Impact Assessment (DPIA) for high-risk AI projects, such as those involving sensitive data or automated decision-making.\nAssess and mitigate bias in AI outputs, keep clear records of decisions, and consult Information Compliance for novel or complex use cases.\nArtificial Intelligence is embedded in many tools we use daily, often invisibly. Used well, it saves time and improves productivity ‚Äî but it also introduces compliance risks, especially when personal data or decisions about people are involved. It‚Äôs essential to understand what you can do freely with approved tools, when to involve the data-protection@bristol.ac.uk, and why awareness of ‚Äúhidden AI‚Äù matters.",
    "crumbs": [
      "Privacy & Compliance"
    ]
  },
  {
    "objectID": "pages/500-compliance.html#everyday-ai-use",
    "href": "pages/500-compliance.html#everyday-ai-use",
    "title": "Privacy & Compliance",
    "section": "Everyday AI Use",
    "text": "Everyday AI Use\nYou can use University-approved tools such as Microsoft Copilot and Teams transcription for routine tasks. These operate within the University‚Äôs secure Microsoft 365 environment, so prompts and outputs are protected under our tenancy. Examples of safe, everyday use include:\n\nSummarising documents\nDrafting content\nGenerating ideas\nTranscribing meetings\n\nAlways review outputs before sharing ‚Äî AI can misinterpret or invent details. Treat its work as a draft, not a final version.\n\nStay SAFE\n\nS ‚Äì Stick to approved tools: Use University-approved platforms like Copilot and Teams transcription.\nA ‚Äì Always review outputs: Check for errors, bias, and hallucinations before sharing.\nF ‚Äì Follow academic integrity: Disclose AI use in teaching or research where relevant.\nE ‚Äì Enter minimal data: Keep personal and confidential data to a minimum, even within approved tools. Anything entered into Copilot is subject to legal processes, including Freedom of Information requests (FOI).\n\n\n\n\n\n\n\nImportantUniversity of Bristol guidance\n\n\n\nNever share these with AI tools:\nüö´ Personal data: Student records, staff information, health data\nüö´ Confidential research: Unpublished findings, grant applications under review\nüö´ Commercial sensitive: Partnership agreements, financial information\nüö´ Legal privileged: Legal advice, disciplinary proceedings\nüö´ Security sensitive: Passwords, system configurations, access credentials\nFind more ‚Üí",
    "crumbs": [
      "Privacy & Compliance"
    ]
  },
  {
    "objectID": "pages/500-compliance.html#privacy-risk-assessment",
    "href": "pages/500-compliance.html#privacy-risk-assessment",
    "title": "Privacy & Compliance",
    "section": "Privacy Risk Assessment",
    "text": "Privacy Risk Assessment\nNot all AI use is low risk. If you plan to use a new tool or apply an approved tool in a novel way, speak to the data-protection@bristol.ac.uk before you start.\nYou will need to complete a Data Protection Impact Assessment (DPIA) for high-risk processing, such as:\n\nAutomated decision-making (even with human checking)\nLarge-scale processing of sensitive data\nCombining datasets for profiling or prediction\n\nIndicators you need compliance checks:\n\nAI processes significant personal or special category data\nAI influences decisions about people (grading, recruitment, disciplinary)\nCombining multiple datasets or profiling individuals\nProject feels novel, complex, or high risk\n\nUnder UK GDPR and ICO guidance, high-risk processing must be assessed for lawfulness, fairness, transparency, and accountability. A DPIA helps identify risks and document controls.\nKey requirements for high-risk AI use:\n\nProvide meaningful human review for automated decisions\nOffer clear privacy information and opt-out options\nExplain AI logic and impact in plain English\nAssess and mitigate bias in training data and outputs _ Record roles, responsibilities, DPIAs, and decisions\nConsult the ICO if risks cannot be mitigated",
    "crumbs": [
      "Privacy & Compliance"
    ]
  },
  {
    "objectID": "pages/500-compliance.html#intellectual-property-and-academic-integrity",
    "href": "pages/500-compliance.html#intellectual-property-and-academic-integrity",
    "title": "Privacy & Compliance",
    "section": "Intellectual Property and Academic Integrity",
    "text": "Intellectual Property and Academic Integrity\nAI-generated content raises questions about ownership and copyright. Under UK law, works created by AI without human authorship may not attract copyright protection. If you use AI to assist with creating materials, you remain responsible for:\n\nRights to any source material used\nAvoiding infringement of third-party IP\nAcknowledging AI use where required by academic integrity policies\n\nFor research and teaching, treat AI outputs as supporting material, not original scholarship.",
    "crumbs": [
      "Privacy & Compliance"
    ]
  },
  {
    "objectID": "pages/500-compliance.html#checklists",
    "href": "pages/500-compliance.html#checklists",
    "title": "Privacy & Compliance",
    "section": "Checklists",
    "text": "Checklists\nEveryday AI Use\n‚úÖ Use University-approved tools (Copilot, Teams transcription)\n‚úÖ Review AI outputs before sharing\n‚úÖ Minimise personal data\n‚úÖ Be transparent‚Äîdisclose AI use in academic work\n‚úÖ Watch for hidden AI features\nYou Need a DPIA\nIf you tick yes to any, contact Information Compliance before starting:\n\nWill AI process special category data?\n\nWill AI influence decisions about people?\n\nWill AI combine multiple datasets or profile individuals?\n\nIs the project novel, complex, or high risk?\n\nWill outputs have legal or significant effects?\n\nDoes the project involve bias analysis or fairness checks?\n\nWill you need to explain AI decisions to individuals?\n\n\nScenarios\n\n\n\n\n\n\n\n\nScenario\nCategory\nAction Required\n\n\n\n\nUsing Copilot to draft lecture notes\nEveryday use\nReview outputs, treat as source material\n\n\nSummarising published research with Copilot\nEveryday use\nCheck accuracy\n\n\nTeams transcription for meeting minutes\nEveryday use\nReview for errors before ratifying\n\n\nGenerating ideas for teaching materials\nEveryday use\nTreat as source material, check references\n\n\nUploading student records into AI tool\nHigh-risk / Novel use\nConsult Information Compliance\n\n\nUsing AI to shortlist job applicants\nHigh-risk / Novel use\nConsult Information Compliance\n\n\nCombining datasets for profiling\nHigh-risk / Novel use\nConsult Information Compliance\n\n\nAI making decisions with legal/significant effects\nHigh-risk / Novel use\nConsult Information Compliance\n\n\nProcessing special category data (health, ethnicity)\nHigh-risk / Novel use\nConsult Information Compliance\n\n\nDeveloping a new AI model for research\nHigh-risk / Novel use\nConsult Information Compliance",
    "crumbs": [
      "Privacy & Compliance"
    ]
  },
  {
    "objectID": "pages/500-compliance.html#data-privacy-and-security",
    "href": "pages/500-compliance.html#data-privacy-and-security",
    "title": "Privacy & Compliance",
    "section": "Data Privacy and Security",
    "text": "Data Privacy and Security\nWhen you use AI tools for work-related tasks, whether through web interfaces, APIs, or integrated applications, your data typically:\n\nTravels over the internet to AI company servers\nGets processed by AI systems you don‚Äôt control\n\nMay be stored temporarily or permanently by the AI provider\nCould potentially be used for training future AI models\nMight be subject to different legal jurisdictions\n\nUnderstanding this data flow is crucial for making informed decisions about what information you share with AI systems, especially when handling sensitive data or proprietary content. Always evaluate these risks and follow University guidance.\n\n\n\n\n\n\nWarningData Privacy Risk\n\n\n\nLow Risk ‚úÖ\n\nPublic information already available online\n\nGeneral knowledge questions\n\nAnonymous, aggregated data\n\nPublished research you‚Äôre summarizing\n\nMedium Risk ‚ö†Ô∏è\n\nInternal documents with no personal data\n\nDraft policies before approval\n\nAcademic work in progress (with proper disclosure)\n\nHigh Risk ‚ùå\n\nAny personal or confidential information\n\nUnpublished research data\n\nStudent or staff records\n\nCommercially sensitive material\n\n\n\n\nData Protection Best Practices\nImplementing proper data protection measures helps you minimizing privacy and security risks. Consider:\n\nUse institutional accounts when available (better data protection)\nAnonymize data before sharing with AI tools\nUse placeholder data for testing and training\nCheck privacy policies of AI tools you use\nFollow university guidelines on data classification\nConsider on-premises alternatives for sensitive work",
    "crumbs": [
      "Privacy & Compliance"
    ]
  },
  {
    "objectID": "pages/200-tools.html",
    "href": "pages/200-tools.html",
    "title": "LLMs tools",
    "section": "",
    "text": "Large Language Models (LLMs) have been rapidly introduced to workplace environments since ChatGPT‚Äôs breakthrough launch in late 2022. The landscape is quickly evolving, with major tech companies and AI startups releasing increasingly sophisticated models tailored for different use needs. When selecting an LLM consider factors such as data privacy policies, integration capabilities, cost structure, and specific feature sets that align with the University‚Äôs workflows. The following list covers the some of the most prominent options available today.\n\nMicrosoft Copilot copilot.microsoft.com\n\nFirst Release: March 2023\nStrengths: Deep integration with Microsoft Office suite\nBest for: Document creation, email assistance, Office workflows, enterprise productivity\nConsiderations: Enterprise versions offer better data protection; requires Microsoft 365 subscription\n\n\n\n\n\n\n\nImportantUniversity of Bristol AI guidance\n\n\n\nThe only recommended tool for the time being is Microsoft Copilot if you are looking to use generative AI to minimise data and privacy concerns.\nThe goal isn‚Äôt to avoid AI tools entirely, but to use them responsibly and effectively. Do not use AI apps, solutions, platforms that have not been formally approved by the University with personal data or any other confidential or sensitive information.\nFind more ‚Üí\n\n\n\n\nChatGPT (OpenAI) chat.openai.com\n\nFirst Release: November 2022\nStrengths: Conversational, good for general tasks, coding assistance\nBest for: Writing assistance, brainstorming, general Q&A, code generation\nConsiderations: Data usage policies vary by version; enterprise versions available\n\n\n\nClaude (Anthropic) claude.ai\n\nFirst Release: March 2023\nStrengths: Helpful, harmless, honest approach; excellent for analysis\nBest for: Analysis, research assistance, ethical reasoning, document processing\nConsiderations: Strong focus on safety and accuracy; large context window\n\n\n\nGoogle Gemini gemini.google.com\n\nFirst Release: December 2023\nStrengths: Multimodal capabilities, integration with Google Workspace\nBest for: Research, document analysis, creative tasks, Google ecosystem integration\nConsiderations: Various models available (Nano, Pro, Ultra) with different capabilities\n\n\n\nGoogle NotebookLM notebooklm.google.com\n\nFirst Release: July 2023\nStrengths: Document-grounded AI, source-based research, podcast-style audio summaries\nBest for: Research analysis, document synthesis, creating audio overviews, academic work\nConsiderations: Works with your uploaded sources; Plus version offers 5x higher usage limits\n\n\n\nMeta Llama llama.meta.com\n\nFirst Release: February 2023\nStrengths: Open-source, customizable, strong performance\nBest for: Custom applications, on-premise deployment, research\nConsiderations: Requires technical expertise; various sizes available (7B to 405B parameters)\n\n\n\nPerplexity AI perplexity.ai\n\nFirst Release: August 2022\nStrengths: Real-time web search integration, source citations\nBest for: Research, fact-checking, current information retrieval\nConsiderations: Excellent for staying current with latest information\n\n\n\n\n\nProper Attribution\nWhen artificial intelligence tools significantly contribute to your work, proper attribution is essential for maintaining transparency and ethical standards. Failing to acknowledge AI assistance where it played a substantial role can mislead audiences about the true nature of your work‚Äôs creation.\nExample Attribution: ‚ÄúInitial drafts of this literature review were developed with assistance from Claude (Sonnet 4). All sources were independently verified, analysis was conducted by the author, and conclusions represent the author‚Äôs professional judgment.‚Äù\nDo you require more thorough record-keeping? Use a documentation form instead\n\n LLM_Usage_Documentation_Form.docx",
    "crumbs": [
      "LLMs tools"
    ]
  },
  {
    "objectID": "pages/800-resources.html",
    "href": "pages/800-resources.html",
    "title": "Resources",
    "section": "",
    "text": "Guidelines\n\nUniversity of Bristol guidance\n\nIT Services Generative AI Guidance (UoB login required)\nData Protection Policy\nData Protection Privacy Notices\nInformation Security Policies\nUniversity Guidance on Generative AI in Education\nStudy Skills Resource on Using AI for Students\nAcademic Integrity Policy\n\n\n\nOther guidance\n\nRussell Group Principles on generative AI in education\nUKRIO Embracing AI with integrity\n\n\n\n\nTraining resources\n\nPrompt Engineering\n\nOpenAI Prompt Engineering Guide\nAnthropic‚Äôs Guide to Claude\nGoogle‚Äôs AI Principles and Practices\n\n\n\nOther\n\nOn the reg - podcast\nOne useful thing - blog\nAI Ethics Lab\nPartnership on AI",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "pages/600-ethics.html",
    "href": "pages/600-ethics.html",
    "title": "Ethics & Environmental Impact",
    "section": "",
    "text": "NoteKey Takeaways\n\n\n\n\nEnvironmental cost is significant - Use AI efficiently, batch queries, choose smaller models when appropriate.\nAI has biases - Watch for gender, racial, socioeconomic, and geographic biases; request diverse examples explicitly.\nMaintain human oversight - AI should enhance, not replace, your expertise and critical judgment.\nConsider ethical implications - Be mindful of data rights, labor practices, and the value of human communication.",
    "crumbs": [
      "Ethics & Environmental Impact"
    ]
  },
  {
    "objectID": "pages/600-ethics.html#section",
    "href": "pages/600-ethics.html#section",
    "title": "Ethics & Environmental Impact",
    "section": "",
    "text": "Exercise 5: Reflective Exercise\nTo explore the complex human dimensions of AI use, consider how others might feel about being on the receiving end of AI-generated content in sensitive contexts. You could hold a discussion exploring various scenarios, such as:\n\nUsing AI to summarize CVs for job applicants.\nUsing AI (without sharing any personal details) to draft an email response to a student about their extenuating circumstances.\nUsing AI to write the first draft of a dissertation (you are the supervisor).",
    "crumbs": [
      "Ethics & Environmental Impact"
    ]
  },
  {
    "objectID": "pages/900-summary.html",
    "href": "pages/900-summary.html",
    "title": "Summary",
    "section": "",
    "text": "Congratulations on completing this course on responsible LLM use. You now have the knowledge and tools to:\n\nUnderstand LLMs and their limitations\nProvide effective context while maintaining transparency\nEngineer prompts that enhance your capabilities\nNavigate ethical considerations responsibly\n\nSuccessful AI implementation requires ongoing commitment to learning, adaptation, and ethical reflection. The technology will continue to evolve, but our commitment to responsible use must remain constant.\n\nWhat are your next steps?\nImmediate (next 30 days):\n\nReview current AI guidance in your work\nIdentify opportunities for responsible AI application\n\nShort Term (next 3 months):\n\nImplement AI tools in low-risk applications\nDevelop personal templates and workflows\nShare experiences with colleagues\n\nLong Term (next 6-12 months):\n\nMentor others in responsible AI usage\nContribute to department policy development\nPursue advanced AI literacy training",
    "crumbs": [
      "Summary"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction",
    "section": "",
    "text": "Welcome to this training course on the responsible use of Artificial Intelligence (AI) at the University.\nThe term Artificial Intelligence refers to computer systems that can perform tasks typically requiring human intelligence, such as understanding language, recognizing patterns, and making decisions. While the AI field has many years of research and development behind it, today‚Äôs increased popularity is largely driven by generative AI models‚Äîsystems that can create new content like text, images, and code based on the patterns they‚Äôve learned from vast amounts of data. You‚Äôve probably heard of and used tools like ChatGPT and Copilot‚Äîhere we‚Äôll learn how to use them effectively and in compliance with University of Bristol guidance.\n\n\n\n\n\n\nImportantUniversity of Bristol AI guidance\n\n\n\nThis course is built on the foundation of the University‚Äôs commitment to responsible AI use. Our approach emphasizes:\n\nTransparency: Being open about when and how AI is used\nCritical Thinking: Using AI to support, not replace, intellectual rigor\nAcademic and Professional Integrity: Maintaining the highest standards of work\nEthical Considerations: Being mindful of bias, privacy, and environmental impact\n\nFind more ‚Üí\n\n\n\nLearning Objectives\nBy the end of this course, you will be able to:\n\nUnderstand what LLMs are and their key capabilities and limitations\nApply responsible practices when using AI tools in your work\nCraft effective prompts that enhance rather than replace critical thinking\nNavigate ethical considerations including bias, privacy, and environmental impact\nImplement University of Bristol policies and guidelines in your AI usage\n\n\n\nAbout this course\nThese course materials have been designed and developed by Pau Erola, PhD (Jean Golding Institute, University of Bristol).\nThanks to Huw Day for his feedback and recommendations on ethics and environmental impact. Thanks to Leo Gorman, Will Chapman, Rita Rasteiro, Richard Lane, James Thomas and Patricia Holley for their valuable comments and corrections.\nWe used the enhancement of AI in alignment with our institutional guidance:\n\nMicrosoft Copilot (GPT-4 & GPT-5)‚Äì Generation of synthetic datasets, documents and examples\nClaude (Sonnet 4) ‚Äì Writing assistance, examples generation\nChatGPT (GPT-5) ‚Äì Generation of figures\n\nFor queries related to this course please contact jgi-training@bristol.ac.uk.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "pages/400-conversational.html",
    "href": "pages/400-conversational.html",
    "title": "Conversational Learning",
    "section": "",
    "text": "NoteKey Takeaways\n\n\n\n\nUse AI as learning partner, not task executor - Ask ‚Äúwhy‚Äù and ‚Äúhow‚Äù to understand processes, not just get outputs\nShift from efficiency to learning mindset - Move from ‚Äúgive me the answer‚Äù to ‚Äúwalk me through the thinking‚Äù\nChallenge AI reasoning - Test explanations, ask about limitations, play devil‚Äôs advocate\nMost people approach AI with a transactional mindset, asking for document summaries, presentation outlines, email drafts, or quick recommendations. While this approach produces immediate outputs, it creates a fundamental problem: you receive results without gaining insight into the underlying processes that created them.\nThe learning partnership approach transforms this dynamic entirely. Instead of simply requesting outputs, you engage AI as a collaborative thinking partner. You might ask an AI to explain why it structured a summary in a particular way, what principles guided its outline choices, or how it determined the appropriate tone for professional communication. This shift in questioning style ensures that every interaction becomes an opportunity to understand processes and develop transferable skills.\nThe difference in outcomes is profound. Traditional approaches leave you dependent on AI for similar future tasks, while learning partnerships build your capacity to handle increasingly complex challenges independently.",
    "crumbs": [
      "Conversational Learning"
    ]
  },
  {
    "objectID": "pages/400-conversational.html#section",
    "href": "pages/400-conversational.html#section",
    "title": "Conversational Learning",
    "section": "",
    "text": "Exercise 4: Conversational Learning Practice\nScenario: You need to improve staff participation in development courses.\n1. Traditional Approach. First, ask AI directly: ‚ÄúGive me strategies to increase staff participation in development courses.‚Äù\n2. Learning Partnership Approach. Now, have a learning conversation. Use these conversation starters:\n\nExplore the problem: ‚ÄúHelp me understand why staff might be reluctant to participate. What factors typically influence participation?‚Äù\nQuestion assumptions: ‚ÄúI‚Äôm assuming low participation is a problem - help me examine this assumption. When might quiet classrooms actually be effective?‚Äù\nBuild understanding: ‚ÄúWhat principles of group dynamics and learning psychology should guide my approach?‚Äù\n\n3. Reflection. Compare the two approaches:\n\nWhich gave you more insight into the underlying issues?\nWhich better prepared you to handle similar challenges in the future?\n\n\n\n\n\n\n\nCautionSolution example\n\n\n\n\n\nBased on Copilot (GPT-4 architecture).\n\nIn 200 words, give me strategies to increase staff participation in development courses.\n\n\n\n\n\n\n\nTo increase staff participation in development courses, focus on relevance, accessibility, and motivation. Begin by aligning courses with individual career goals and team objectives. When staff see how training supports their growth or contributes to project success, they‚Äôre more likely to engage.\nMake learning convenient by offering flexible formats‚Äîonline modules, short sessions, or on-demand access. Ensure courses are scheduled during work hours and don‚Äôt conflict with key responsibilities.\nLeadership plays a key role: managers should actively promote courses, participate themselves, and recognize staff who engage. This sets a positive example and reinforces a culture of learning.\nIncentivize participation with certificates, digital badges, or public recognition. Link course completion to tangible benefits like eligibility for new roles or responsibilities.\nRegularly communicate the value of development opportunities through internal channels. Use success stories or testimonials to show real-world impact.\nFinally, gather feedback to improve course offerings and involve staff in shaping future content. When employees feel heard and see their input reflected, they‚Äôre more likely to participate.\n\n\n\n\nIn 200 words, help me understand why staff might be reluctant to participate. What factors typically influence participation?\n\n\n\n\n\n\n\nStaff may be reluctant to participate in development courses due to a mix of practical constraints and psychological factors. One of the most common barriers is lack of time‚Äîemployees often feel overwhelmed by daily responsibilities and may not see how training fits into their workload. If courses are scheduled during busy periods or require significant time commitments, participation drops.\nAnother key factor is perceived relevance. Staff are less likely to engage if they don‚Äôt see how the course content applies to their role or career goals. Generic or outdated offerings can feel disconnected from real work challenges.\nManagerial support also plays a crucial role. If leaders don‚Äôt actively encourage participation or fail to prioritize learning, staff may assume it‚Äôs not valued. Conversely, when managers model engagement and link training to performance reviews or promotions, uptake improves.\nFear of failure or judgment can also deter participation, especially in group settings or courses with assessments. Some staff may worry about exposing gaps in their knowledge.\nFinally, accessibility issues‚Äîsuch as limited formats, lack of remote options, or unclear instructions‚Äîcan make courses hard to attend.\n\n\n\n\nI‚Äôm assuming low participation is a problem - help me examine this assumption. When might quiet classrooms actually be effective? Don‚Äôt use more than 200 words.\n\n\n\n\n\n\n\nLow participation in development courses is often seen as a problem, but it‚Äôs worth examining whether that assumption always holds. A quiet classroom doesn‚Äôt necessarily mean disengagement‚Äîit can reflect deep concentration, a preference for self-paced learning, or a mismatch between delivery style and learning preferences.\nSome staff may prefer asynchronous formats, such as recorded sessions or written materials, which don‚Äôt require visible participation. Others may be absorbing content passively before applying it practically. In highly skilled or research-focused environments, staff might already be learning informally through projects, peer collaboration, or independent study.\nAdditionally, low attendance might indicate that the course isn‚Äôt needed, rather than a lack of interest. If staff already possess the skills being taught, or if the course doesn‚Äôt align with current priorities, opting out can be a rational choice.\nRather than focusing solely on numbers, it‚Äôs more useful to assess impact‚Äîare those who attend applying what they learn? Are staff developing in other ways? Quiet classrooms can still be effective if they support meaningful, relevant learning.\n\n\n\n\nWhat principles of group dynamics and learning psychology should guide my approach? Don‚Äôt use more than 200 words.\n\n\n\n\n\n\n\nYour approach to increasing participation in development courses should be guided by key principles from group dynamics and learning psychology:\n\nSocial Influence & Norms. People are more likely to engage when they see peers doing the same. Creating visible norms around participation‚Äîsuch as team-wide involvement or manager endorsement‚Äîcan foster a sense of collective commitment.\nPsychological Safety. Staff need to feel safe to ask questions, make mistakes, and share ideas. A supportive learning environment encourages participation, especially in group settings.\nSelf-Determination Theory. Motivation increases when learners feel autonomy, competence, and relatedness. Offer choices in course formats, ensure content builds confidence, and foster connection through collaborative activities.\nConstructivist Learning. People learn best when they actively construct knowledge through experience. Encourage reflection, discussion, and application to real tasks rather than passive consumption.\nGroup Cohesion. Strong group bonds improve engagement. Use team-based learning, peer mentoring, or shared goals to build trust and accountability.",
    "crumbs": [
      "Conversational Learning"
    ]
  },
  {
    "objectID": "pages/700-examples.html",
    "href": "pages/700-examples.html",
    "title": "Examples",
    "section": "",
    "text": "A template to analyse and present workshop feedback\nThis is a generic template you can use to generate a report from feedback forms. You can try it using this synthetic dataset\n\n synthetic_workshop_feedback.xlsx.\n\n\n\n\n\n\n\nImportantData upload checklist\n\n\n\nBefore uploading any data file, verify that:\n\nYou have permission to use this content for your purposes\nAll personal identifiers have been removed (names, email addresses, phone numbers, etc.)\nNo sensitive or confidential information is included that users may have entered\nThe content complies with privacy regulations and institutional policies\n\n\n\n\nYou are a skilled analyst specialising in interpreting workshop participant feedback. You excel at identifying recurring themes, and spotting unusual, noteworthy, or conflicting viewpoints that emerge from responses.\nYour Analysis Will Include:\nStatistical Summary: Provide theme prevalence and confidence levels in your assessments.\nKey Observations: Identify outlier opinions, contradictory feedback, minority perspectives, and any concerning or unexpected patterns that stand apart from the consensus.\nComprehensive Overview: Deliver an overall assessment with workshop strengths, improvement areas, and actionable recommendations.\nReporting Format:\n\nExecutive summary with key insights\nQuantitative breakdown of responses\nMajor themes with supporting evidence\nNotable observations (unusual/conflicting feedback)\nSpecific recommendations for improvement\nUse graphics\nIn Word format\n\nUse clear, professional language with anonymised examples where helpful. Present findings in British English.\nThe feedback collected is enclosed\n\nMicrosoft Copilot (with GTP-5) example output\n\n Workshop_Feedback_Analysis_Report.docx",
    "crumbs": [
      "Examples"
    ]
  },
  {
    "objectID": "pages/310-prompting.html",
    "href": "pages/310-prompting.html",
    "title": "Prompting Frameworks",
    "section": "",
    "text": "NoteKey Takeaways\n\n\n\n\nHigh-quality prompts eliminate ambiguity - Clear context upfront gets better responses\nUse structured frameworks, e.g.¬†the CLEAR framework, to ensure complete prompts\nNever share sensitive data - No personal records, confidential research, or security information\nHigh-quality prompts that eliminate ambiguity are crucial for getting useful responses from Large Language Models. By providing comprehensive context upfront, you‚Äôre more likely to receive output that matches your requirements.\nScenario: You have been tasked with running a campaign to increase recruitment of European students for your University‚Äôs MSc Engineering programs.\nYou write the initial prompt:\nProblems with this prompt:\nWe can use some frameworks to standardize our queries and make sure they are complete and don‚Äôt forget any relevant details. There‚Äôs no right or wrong approach ‚Äî different frameworks may work better for different AI tools and yourself, so use the one that works better for you.",
    "crumbs": [
      "Prompting Frameworks"
    ]
  },
  {
    "objectID": "pages/310-prompting.html#section",
    "href": "pages/310-prompting.html#section",
    "title": "Prompting Frameworks",
    "section": "",
    "text": "Exercise 3: Building Workplace Prompts\nScenario: You‚Äôre organizing a workshop on ‚ÄúDigital Skills for Academics‚Äù at the University of Bristol.\nTask: Create a prompt to help design the workshop agenda.\nRequirements:\n\nUse the CLEAR framework\nInclude appropriate constraints\nMaintain academic integrity\n\nReflection Questions:\n\nHow do your prompts ensure AI enhances rather than replaces your expertise?\nWhat verification steps would you take for each output?\nHow would you attribute AI assistance appropriately?\n\n\n\n\n\n\n\nCautionSolution example\n\n\n\n\n\nCreate a prompt to help design a workshop on ‚ÄúDigital Skills for Academics‚Äù at the University of Bristol.\n\nContext: I‚Äôm a University of Bristol academic organizing a ‚ÄúDigital Skills for Academics‚Äù workshop for faculty from various disciplines with mixed technical backgrounds.\nLength: Create a detailed 3-hour workshop agenda with 15-30 minute segments.\nExamples: Include interactive elements like hands-on activities and small group discussions, similar to effective pedagogical workshops I‚Äôve attended.\nAction: Design an agenda that balances presentation, demonstration, and practice, progressing from basic to advanced concepts.\nRole: Act as an experienced workshop facilitator specializing in faculty development.\nAdditional Constraints:\n- Maximum 20 participants to allow for individual attention.\n- Must include time for networking and peer learning.\n- Consider accessibility needs and different learning styles.\n- Include evaluation/feedback collection methods.\n- Build in buffer time for technical issues.",
    "crumbs": [
      "Prompting Frameworks"
    ]
  },
  {
    "objectID": "pages/300-context.html",
    "href": "pages/300-context.html",
    "title": "Context matters",
    "section": "",
    "text": "NoteKey Takeaways\n\n\n\n\nContext is all the information you give LLMs to understand your request (role, purpose, audience, requirements)\nBe specific, not vague - Clear context gets relevant responses; vague prompts get generic ones\nRefine iteratively - Start basic, review output, add details, repeat until satisfied\nNever share sensitive data - No personal records, unpublished research, or confidential information\nLarge Language Models work by navigating through vast embedding spaces‚Äîmultidimensional representations of knowledge and concepts. Vague or poorly defined context can lead the model to explore irrelevant areas of this space, producing generic or off-target responses. Well-crafted context act as precise navigation instructions, guiding the model to the most relevant knowledge areas and ensuring outputs that match your specific needs and context.",
    "crumbs": [
      "Context matters"
    ]
  },
  {
    "objectID": "pages/300-context.html#section",
    "href": "pages/300-context.html#section",
    "title": "Context matters",
    "section": "",
    "text": "Exercise 2: Context Writing\nTransform a vague prompt into an effective, contextualised request. Use an AI tool of your choice to observe the difference that context have on your request.\nScenario: You need to create a policy document about flexible working arrangements for your department.\nInitial prompt:\n\nWrite a 1-page-long flexible working policy\n\n\n\n\n\n\n\nCautionSolution example\n\n\n\n\n\n\nInitial prompt\n\nWrite a 1-page-long flexible working policy\n\nSee Claude (Sonnet 4) answer here\n\n flexible-working-policy.pdf\n\n\n\nContextualised prompt\n\nContext. I am a Departmental Operations Manager in the University of Bristol Engineering Department, developing a flexible working policy for our 45 academic staff and 12 professional services staff.\nPurpose. Create a clear policy that supports work-life balance while maintaining research productivity, teaching quality, and team collaboration, complying with university HR policies and employment law.\nAudience. Department staff (mix of early-career and senior academics, technical and administrative professionals) and department leadership who need practical guidance.\nScope. Cover remote work, flexible hours, compressed schedules, and term-time arrangements. Exclude sabbatical leave (covered elsewhere) and temporary adjustments (covered by separate policy).\nFormat. 1 page professional document with clear sections, bullet points for key procedures, and practical examples.\n\nSee Claude (Sonnet 4) answer here\n\n engineering-department-flexible-working-policy.pdf",
    "crumbs": [
      "Context matters"
    ]
  },
  {
    "objectID": "pages/100-llm.html",
    "href": "pages/100-llm.html",
    "title": "What are LLMs?",
    "section": "",
    "text": "NoteKey Takeaways\n\n\n\n\nLLMs are mathematical models of language that maps similar words to nearby positions in a conceptual space\n\nThey predict which words are most likely to follow a given input, or prompt, based on patterns learned from vast amounts of text\nThey work by pattern matching, not true understanding, therefore they are not infallible sources of truth\n\nAlways verify important information from authoritative sources\nBe aware of bias in AI outputs and actively check for it\nUse critical thinking - if something sounds too precise or extreme, investigate further\nAlways follow University of Bristol AI guidance",
    "crumbs": [
      "What are LLMs?"
    ]
  },
  {
    "objectID": "pages/100-llm.html#section",
    "href": "pages/100-llm.html#section",
    "title": "What are LLMs?",
    "section": "",
    "text": "Exercise 1: Identifying LLM Limitations\nScenario: You‚Äôre preparing a briefing document about climate change impacts in Bristol.\nPrompt:\n\nWrite 2 sentences about how climate change is impacting Bristol\n\nReview the below outputs of three different LLM tools and identify potential issues:\n\nWhich output seems most reliable and why?\nWhat red flags can you identify in each response?\nHow would you verify the information before using it professionally?\n\n\nOutput A: ‚ÄúBristol experienced its wettest year on record in 2023, with rainfall 40% above average. The Severn Estuary‚Äôs sea level has risen 15cm since 2000, directly threatening the city center.‚Äù\n\nOutput B: ‚ÄúClimate change will cause Bristol‚Äôs temperature to increase by exactly 3.2¬∞C by 2050, making it uninhabitable for most residents. The city council has already approved plans to relocate the entire population to higher ground.‚Äù\n\nOutput C: ‚ÄúBristol faces increased flooding risks due to climate change. The city has implemented various adaptation measures, though specific impacts vary by neighborhood and depend on global emission scenarios.‚Äù\n\n\n\n\n\n\nCautionSolution example\n\n\n\n\n\nOutput A: ‚ÄúBristol experienced its wettest year on record in 2023, with rainfall 40% above average. The Severn Estuary‚Äôs sea level has risen 15cm since 2000, directly threatening the city center.‚Äù\nContains specific statistics that need verification. While plausible, the exact figures should be fact-checked against official sources.\n‚ö†Ô∏è Specific statistics require verification: ‚ÄúWettest year on record‚Äù and ‚Äú40% above average‚Äù are precise claims that need fact-checking\n‚ö†Ô∏è Sea level measurement: The specific ‚Äú15cm since 2000‚Äù figure should be verified against official sources\n‚ö†Ô∏è Causal claim: Direct threat to city center needs geographic verification\n‚úÖ Generally plausible: The types of impacts described are consistent with climate science\n\nOutput B: ‚ÄúClimate change will cause Bristol‚Äôs temperature to increase by exactly 3.2¬∞C by 2050, making it uninhabitable for most residents. The city council has already approved plans to relocate the entire population to higher ground.‚Äù\nContains obvious hallucinations - overly precise predictions and extreme claims about population relocation that aren‚Äôt realistic.\nüö´ Unrealistic precision: ‚ÄúExactly 3.2¬∞C‚Äù - climate models deal in ranges, not exact predictions\nüö´ Extreme claims: ‚ÄúUninhabitable for most residents‚Äù is hyperbolic and unsupported\nüö´ False information: No evidence of city council relocation plans\nüö´ Hallucination: Appears to invent specific policy decisions\n\nOutput C: ‚ÄúBristol faces increased flooding risks due to climate change. The city has implemented various adaptation measures, though specific impacts vary by neighborhood and depend on global emission scenarios.‚Äù\nMost reliable approach - acknowledges uncertainty, speaks in general terms about known issues, doesn‚Äôt make unsupported specific claims.\n‚úÖ Appropriately general: Makes broad, supportable statements\n‚úÖ Acknowledges uncertainty: ‚ÄúVary by neighborhood‚Äù and ‚Äúdepend on scenarios‚Äù\n‚úÖ Realistic scope: Doesn‚Äôt make unsupported specific claims\n‚úÖ Professional tone: Appropriate for briefing document\n\nKey Learning Points:\n\nBe suspicious of overly precise statistics without sources\nExtreme or alarmist language often indicates hallucination\nThe most useful AI outputs acknowledge uncertainty appropriately\nAlways verify specific factual claims before using professionally",
    "crumbs": [
      "What are LLMs?"
    ]
  }
]